{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZdncPmi8YS-"
   },
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66nIj8A28YTA"
   },
   "source": [
    "## Laboratory 1: Markov chains\n",
    "\n",
    "In the end of the lab, you should export the notebook to a Python script (``File >> Download as >> Python (.py)``). Make sure that the resulting script includes all code written in the tasks marked as \"**Activity n. N**\", together with any replies to specific questions posed. Your file should be named `padi-labKK-groupXXX.py`, where `KK` corresponds to the lab number and the `XXX` corresponds to your group number. Similarly, your homework should consist of a single pdf file named `padi-hwKK-groupXXX.pdf`. You should create a zip file with the lab and homework files and submit it in Fenix **at most 30 minutes after your lab is over**.\n",
    "\n",
    "Make sure to strictly respect the specifications in each activity, in terms of the intended inputs, outputs and naming conventions.\n",
    "\n",
    "In particular, after completing the activities you should be able to replicate the examples provided (although this, in itself, is no guarantee that the activities are correctly completed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39DZKyb68YTA"
   },
   "source": [
    "### 1. The Markov chain model\n",
    "We will use a simplified game inspired in the games StopIT and Insey-Winsey-Spider.\n",
    "\n",
    "The players have several levels to climb (corresponding to steps in a ladder) and want to reach the top level.\n",
    "\n",
    "At each instant the player can decide to go and they throw a dice.\n",
    "After that the player has the possibility to climb a number of steps. But they will only go up if it is a sunny day, if it is a rainy day then they go back to the last safe level.\n",
    "At each instant there is also the option to stop. This makes the current level a safe one.\n",
    "Once the last step is reached the game is won.\n",
    "A stop action will stop again but a go action will reset the game to the initial state corresponding to the level 0 and safe level 0.\n",
    "\n",
    "In this first activity, you will implement your Markov chain model in Python. You will start by loading the transition probability matrix from a `numpy` binary file, using the `numpy` function `load`. You will then consider the state space to consist of all valid indices for the loaded transition matrix, each represented as a string. For example, if the transition probability matrix is $20\\times 20$, the states should include the strings `'0'` to `'19'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrMRHX1u8YTD"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Write a function named `load_chain` that receives, as input, a string corresponding to the name of the file with a transition matrix to be loaded, and a real number $\\gamma$ between $0$ and $1$. Assume that:\n",
    "\n",
    "* The transition matrices in the file have been built from a representation of the game with P[0] corresponding to the transition of the action stop and P[1] for the action go.\n",
    "\n",
    "* For this first lab we do not consider the process of choosing action so we consider that the action are choosen at random with the action go selected with probability $\\gamma$ .\n",
    "\n",
    "Your function should build the transition probability matrix for the chain by combining the two actions using the value of $\\gamma$. Your function should then return, as output, a two-element tuple corresponding to the Markov chain, where:\n",
    "\n",
    "* ... the first element is a tuple containing an enumeration of the state-space (i.e., each element of the tuple corresponds to a state of the chain, represented as a string);\n",
    "* ... the second element is a `numpy` array corresponding to the transition probability matrix for the chain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1738237771000,
     "user": {
      "displayName": "Manuel Lopes",
      "userId": "09390394117258312728"
     },
     "user_tz": 0
    },
    "id": "ZVbYl_578YTE",
    "outputId": "7b00d2e0-74c6-401d-c476-d12f92a6f542",
    "ExecuteTime": {
     "end_time": "2025-03-13T17:57:26.816325Z",
     "start_time": "2025-03-13T17:57:26.809600Z"
    }
   },
   "source": [
    "# Add your code here.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_chain(file, gamma):\n",
    "    transition_matrix = np.load(file)\n",
    "    transition_matrix_final = (1 - gamma) * transition_matrix[0] + gamma * transition_matrix[1]\n",
    "    state_space = tuple(str(i) for i in range(transition_matrix_final.shape[0]))\n",
    "\n",
    "    return state_space, transition_matrix_final"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T17:57:05.276869Z",
     "start_time": "2025-03-13T17:57:05.262465Z"
    }
   },
   "source": [
    "print('- Mgo - always select go -')\n",
    "Mgo = load_chain('StopITSpider02.npy', 1)\n",
    "print('Number of states:', len(Mgo[0]))\n",
    "print('States:', Mgo[0])\n",
    "print('Transition probabilities of state \"0\":')\n",
    "print(Mgo[1][0])\n",
    "\n",
    "import numpy.random as rand\n",
    "\n",
    "rand.seed(42)\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "Mgostop = load_chain('StopITSpider02.npy', 0.5)\n",
    "print('Number of states:', len(Mgostop[0]))\n",
    "x = rand.randint(len(Mgostop[0]))\n",
    "print('Random state:', Mgostop[0][x])\n",
    "print(f'Transition probabilities in random state {x}:')\n",
    "print(Mgostop[1][x, :])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mgo - always select go -\n",
      "(2, 100, 100)\n",
      "Number of states: 100\n",
      "States: ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99')\n",
      "Transition probabilities of state \"0\":\n",
      "[0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "- Mgostop - select go half of the time -\n",
      "(2, 100, 100)\n",
      "Number of states: 100\n",
      "Random state: 51\n",
      "Transition probabilities in random state 51:\n",
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.5 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.1 0.  0.  0.  0.  0.  0.  0.  0. ]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoVWoLUv8YTF"
   },
   "source": [
    "We provide below an example of application of the function that you can use as a first \"sanity check\" for your code. Note, however, that the fact that you can replicate the examples below is not indicative that your code is correct. Moreover, your code will be tested with networks of different sizes, so **make sure not to hard-code the size of the environments into your code**.\n",
    "\n",
    "\n",
    "```python\n",
    "print('- Mgo - always select go -')\n",
    "Mgo = load_chain('StopITSpider02.npy', 1)\n",
    "print('Number of states:', len(Mgo[0]))\n",
    "print('Transition probabilities:')\n",
    "print(Mgo[1])\n",
    "\n",
    "import numpy.random as rand\n",
    "\n",
    "rand.seed(42)\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "Mgostop = load_chain('StopITSpider02.npy', 0.5)\n",
    "print('Number of states:', len(Mgostop[0]))\n",
    "x = rand.randint(len(Mgostop[0]))\n",
    "print('Random state:', Mgostop[0][x])\n",
    "print('Transition probabilities in random state:')\n",
    "print(Mgostop[1][x, :])\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "- Mgo - always select go -\n",
    "Number of states: 100\n",
    "Transition probabilities:\n",
    "[[0.2 0.  0.  ... 0.  0.  0. ]\n",
    " [0.  0.  0.  ... 0.  0.  0. ]\n",
    " [0.  0.  0.  ... 0.  0.  0. ]\n",
    " ...\n",
    " [1.  0.  0.  ... 0.  0.  0. ]\n",
    " [1.  0.  0.  ... 0.  0.  0. ]\n",
    " [1.  0.  0.  ... 0.  0.  0. ]]\n",
    "- Mgostop - select go half of the time -\n",
    "Number of states: 100\n",
    "Random state: 51\n",
    "Transition probabilities in random state:\n",
    "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.\n",
    " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    " 0.  0.5 0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1\n",
    " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0.\n",
    " 0.  0.1 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions might be useful to convert the state representation. For instance the state with the index 10 can also be represented as 1(0) meaning that the player is in the level 1 with safe level 0. State index 22 corresponds to being in level 2 with safe level 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T12:44:14.063204Z",
     "start_time": "2025-03-08T12:44:14.049577Z"
    }
   },
   "source": [
    "# Auxiliary function to convert state representation to state index\n",
    "import numpy as np\n",
    "\n",
    "Lm = 10\n",
    "\n",
    "def observ2state(observ):\n",
    "    dimsizes = [Lm, Lm]\n",
    "    return np.ravel_multi_index(observ, dimsizes)\n",
    "\n",
    "observ = (3, 5)\n",
    "estado = observ2state(observ) # 35\n",
    "print(f\"observ2state {observ}: {estado}\")\n",
    "\n",
    "# Auxiliary function to convert state index to state representation\n",
    "def state2observ(state):\n",
    "    dimsizes = [Lm, Lm]\n",
    "    return np.unravel_index(int(state), dimsizes)\n",
    "\n",
    "state = 35\n",
    "observ = state2observ(state) # (3, 5)\n",
    "print(f\"state2observ {state}: {observ}\")\n",
    "\n",
    "# Auxiliary function to print a sequence of states\n",
    "def printTraj(seq):\n",
    "    ss = \"\"\n",
    "    for st in seq:\n",
    "        ss += printState(st) + \"\\n\"\n",
    "\n",
    "    return ss\n",
    "\n",
    "ss = printTraj(('0', '20', '40'))\n",
    "print(ss)\n",
    "\n",
    "# Auxiliary function to print a state\n",
    "def printState(state):\n",
    "    if type(state) in [list,tuple]:\n",
    "        l = state[0]\n",
    "        s = state[1]\n",
    "    else:\n",
    "        l,s = state2observ(state)\n",
    "\n",
    "    return \"%d (%d)\" % (l, s)\n",
    "\n",
    "printState(state)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observ2state (3, 5): 35\n",
      "state2observ 35: (3, 5)\n",
      "0 (0)\n",
      "2 (0)\n",
      "4 (0)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3 (5)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR750QFd8YTG"
   },
   "source": [
    "In the next activity, you will use the Markov chain model to evaluate the likelihood of any given path for the player.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Write a function `prob_trajectory` that receives, as inputs,\n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a trajectory, corresponding to a sequence of states (i.e., a tuple or list of strings, each string corresponding to a state).\n",
    "\n",
    "Your function should return, as output, a floating point number corresponding to the probability of observing the provided trajectory, taking the first state in the trajectory as initial state.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fJZuw3st8YTG",
    "outputId": "aa904a53-5904-420e-cb0f-dc6d00f2bbe4",
    "ExecuteTime": {
     "end_time": "2025-03-08T12:45:35.148230Z",
     "start_time": "2025-03-08T12:45:35.142698Z"
    }
   },
   "source": [
    "# Add your code here.\n",
    "def prob_trajectory(markov_chain, trajectory):\n",
    "    markov_chain_prob = markov_chain[1]\n",
    "    prob = 1\n",
    "    for i in range(len(trajectory) - 1):\n",
    "        prob *= markov_chain_prob[int(trajectory[i])][int(trajectory[i+1])]\n",
    "\n",
    "    return prob"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T12:44:18.934865Z",
     "start_time": "2025-03-08T12:44:18.925986Z"
    }
   },
   "source": [
    "print('- Mgo - always select go -')\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0):\", prob_trajectory(Mgo, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-0(0)-2(0):\", prob_trajectory(Mgo, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-2(2):\", prob_trajectory(Mgo, ('0', '20', '22')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4):\", prob_trajectory(Mgo, ('0', '20', '40', '44','64')))\n",
    "print(\"Prob. of trajectory 6(0)-8(0)-0(0):\", prob_trajectory(Mgo, ('60','80','0')))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0):\", prob_trajectory(Mgostop, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-0(0)-2(0):\", prob_trajectory(Mgostop, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-2(2):\", prob_trajectory(Mgostop, ('0', '20', '22')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4):\", prob_trajectory(Mgostop, ('0', '20', '40', '44','64')))\n",
    "print(\"Prob. of trajectory 6(0)-8(0)-0(0):\", prob_trajectory(Mgostop, ('60','80','0')))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mgo - always select go -\n",
      "Prob. of trajectory 0(0)-2(0)-4(0): 0.04000000000000001\n",
      "Prob. of trajectory 0(0)-0(0)-2(0): 0.04000000000000001\n",
      "Prob. of trajectory 0(0)-2(0)-2(2): 0.0\n",
      "Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4): 0.0\n",
      "Prob. of trajectory 6(0)-8(0)-0(0): 0.04000000000000001\n",
      "- Mgostop - select go half of the time -\n",
      "Prob. of trajectory 0(0)-2(0)-4(0): 0.010000000000000002\n",
      "Prob. of trajectory 0(0)-0(0)-2(0): 0.010000000000000002\n",
      "Prob. of trajectory 0(0)-2(0)-2(2): 0.05\n",
      "Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4): 0.0005000000000000001\n",
      "Prob. of trajectory 6(0)-8(0)-0(0): 0.010000000000000002\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxTq_g9r8YTH"
   },
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "print('- Mgo - always select go -')\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0):\", prob_trajectory(Mgo, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-0(0)-2(0):\", prob_trajectory(Mgo, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-2(2):\", prob_trajectory(Mgo, ('0', '20', '22')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4):\", prob_trajectory(Mgo, ('0', '20', '40', '44','64')))\n",
    "print(\"Prob. of trajectory 6(0)-8(0)-0(0):\", prob_trajectory(Mgo, ('60','80','0')))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0):\", prob_trajectory(Mgostop, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-0(0)-2(0):\", prob_trajectory(Mgostop, ('0', '20', '40')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-2(2):\", prob_trajectory(Mgostop, ('0', '20', '22')))\n",
    "print(\"Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4):\", prob_trajectory(Mgostop, ('0', '20', '40', '44','64')))\n",
    "print(\"Prob. of trajectory 6(0)-8(0)-0(0):\", prob_trajectory(Mgostop, ('60','80','0')))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "- Mgo - always select go -\n",
    "Prob. of trajectory 0(0)-2(0)-4(0): 0.04000000000000001\n",
    "Prob. of trajectory 0(0)-0(0)-2(0): 0.04000000000000001\n",
    "Prob. of trajectory 0(0)-2(0)-2(2): 0.0\n",
    "Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4): 0.0\n",
    "Prob. of trajectory 6(0)-8(0)-0(0): 0.04000000000000001\n",
    "- Mgostop - select go half of the time -\n",
    "Prob. of trajectory 0(0)-2(0)-4(0): 0.010000000000000002\n",
    "Prob. of trajectory 0(0)-0(0)-2(0): 0.010000000000000002\n",
    "Prob. of trajectory 0(0)-2(0)-2(2): 0.05\n",
    "Prob. of trajectory 0(0)-2(0)-4(0)-4(4)-6(4): 0.0005000000000000001\n",
    "Prob. of trajectory 6(0)-8(0)-0(0): 0.010000000000000002\n",
    "```\n",
    "\n",
    "Note that your function should work with **any** Markov chain that is specified as a tuple like the one from Activity 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIo0ytP98YTI"
   },
   "source": [
    "### 2. Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7wMn3GL8YTL"
   },
   "source": [
    "The next activities explore the notion of *stationary distribution* for the chain.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 3\n",
    "\n",
    "Write a function `stationary_dist` that receives, as input, a Markov chain in the form of a tuple like the one returned by the function in Activity 1. Your function should return, as output, a `numpy` array corresponding to a row vector containing the stationary distribution for the chain.\n",
    "\n",
    "**Note:** The stationary distribution is a *left* eigenvector of the transition probability matrix associated to the eigenvalue 1. As such, you may find useful the numpy function `numpy.linalg.eig`. Also, recall that the stationary distribution is *a distribution*. You may also find useful the function `numpy.real` which returns the real part of a complex number.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1738237916113,
     "user": {
      "displayName": "Manuel Lopes",
      "userId": "09390394117258312728"
     },
     "user_tz": 0
    },
    "id": "QS4pEmYO8YTM",
    "outputId": "1fce754f-fce7-478a-bb11-4534d47fabab",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T13:04:44.405177Z",
     "start_time": "2025-03-08T13:04:44.397142Z"
    }
   },
   "source": [
    "# Add your code here.\n",
    "def stationary_dist(markov_chain):\n",
    "    transition_matrix = markov_chain[1]\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "    index = np.argmax(np.isclose(eigenvalues, 1))\n",
    "    stationary_vector = np.real(eigenvectors[:, index])\n",
    "\n",
    "    return stationary_vector / np.sum(stationary_vector)# Garante que o vetor final seja uma matriz 1xN"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:04:45.947149Z",
     "start_time": "2025-03-08T13:04:45.931837Z"
    }
   },
   "source": [
    "print('- Mgo - always select go -')\n",
    "u_star = stationary_dist(Mgo)\n",
    "\n",
    "print('Stationary distribution:')\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "u_prime = u_star.dot(Mgo[1])\n",
    "\n",
    "print('Is this a distribution?', np.isclose(np.sum(u_star), 1))\n",
    "\n",
    "print('Most likely state:', Mgo[0][np.argmax(u_star)])\n",
    "print('Probability of being in the last level:', np.sum(u_star[90:]))\n",
    "\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "u_star = stationary_dist(Mgostop)\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "print('Is this a distribution?', np.isclose(np.sum(u_star), 1))\n",
    "\n",
    "print('Most likely state:', Mgostop[0][np.argmax(u_star)])\n",
    "print('Probability of being in the last level:', np.sum(u_star[90:]))\n",
    "\n",
    "u_prime = u_star.dot(Mgostop[1])\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mgo - always select go -\n",
      "Stationary distribution:\n",
      "[ 0.3  -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.06 -0.\n",
      " -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.07 -0.   -0.   -0.\n",
      " -0.   -0.   -0.   -0.   -0.   -0.    0.09 -0.   -0.   -0.   -0.   -0.\n",
      " -0.   -0.   -0.   -0.    0.1  -0.   -0.   -0.    0.   -0.   -0.   -0.\n",
      " -0.   -0.    0.06 -0.   -0.   -0.    0.    0.   -0.   -0.   -0.   -0.\n",
      "  0.07 -0.   -0.   -0.    0.   -0.   -0.   -0.   -0.   -0.    0.06 -0.\n",
      " -0.   -0.    0.    0.   -0.   -0.   -0.   -0.    0.06 -0.   -0.   -0.\n",
      "  0.    0.   -0.   -0.   -0.   -0.    0.12 -0.   -0.   -0.   -0.    0.\n",
      " -0.   -0.   -0.   -0.  ]\n",
      "Is this a distribution? True\n",
      "Most likely state: 0\n",
      "Probability of being in the last level: 0.12493248575731687\n",
      "\n",
      "Is u* * P = u*? True\n",
      "- Mgostop - select go half of the time -\n",
      "[ 0.24 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.02  0.04\n",
      " -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.03  0.    0.04 -0.\n",
      " -0.   -0.   -0.   -0.   -0.   -0.    0.03  0.    0.    0.05 -0.   -0.\n",
      " -0.   -0.   -0.   -0.    0.03  0.    0.    0.01  0.07 -0.   -0.   -0.\n",
      " -0.   -0.    0.01  0.    0.01  0.01  0.01  0.05 -0.   -0.   -0.   -0.\n",
      "  0.01  0.    0.01  0.01  0.01  0.    0.05 -0.   -0.   -0.    0.01  0.\n",
      "  0.    0.01  0.01  0.01  0.    0.05 -0.   -0.    0.01  0.    0.    0.\n",
      "  0.01  0.01  0.01  0.    0.05 -0.    0.01  0.    0.    0.01  0.01  0.01\n",
      "  0.01  0.02  0.02 -0.  ]\n",
      "Is this a distribution? True\n",
      "Most likely state: 0\n",
      "Probability of being in the last level: 0.08293059995179558\n",
      "\n",
      "Is u* * P = u*? True\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm3QL7uY8YTO"
   },
   "source": [
    "Example of application of the function.\n",
    "\n",
    "```python\n",
    "print('- Mgo - always select go -')\n",
    "u_star = stationary_dist(Mgo)\n",
    "\n",
    "print('Stationary distribution:')\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "u_prime = u_star.dot(Mgo[1])\n",
    "\n",
    "print('Is this a distribution?', np.isclose(np.sum(u_star), 1))\n",
    "\n",
    "print('Most likely state:', Mgo[0][np.argmax(u_star)])\n",
    "print('probability of being in the last level:', np.sum(u_star[0][90:]))\n",
    "\n",
    "\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "u_star = stationary_dist(Mgostop)\n",
    "print(np.round(u_star, 2))\n",
    "\n",
    "print('Is this a distribution?', np.isclose(np.sum(u_star), 1))\n",
    "\n",
    "print('Most likely state:', Mgostop[0][np.argmax(u_star)])\n",
    "print('probability of being in the last level:', np.sum(u_star[0][90:]))\n",
    "\n",
    "u_prime = u_star.dot(Mgostop[1])\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "- Mgo - always select go -\n",
    "Stationary distribution:\n",
    "[[ 0.3   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.06 -0.\n",
    "   0.    0.    0.    0.    0.    0.    0.    0.    0.07 -0.    0.    0.\n",
    "   0.    0.    0.    0.    0.    0.    0.09 -0.    0.    0.    0.    0.\n",
    "   0.    0.    0.    0.    0.1  -0.    0.    0.   -0.    0.    0.    0.\n",
    "   0.    0.    0.06 -0.    0.    0.   -0.    0.    0.    0.    0.    0.\n",
    "   0.07 -0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.06 -0.\n",
    "   0.    0.   -0.    0.    0.    0.    0.    0.    0.06 -0.    0.    0.\n",
    "  -0.    0.    0.    0.    0.    0.    0.12 -0.    0.    0.   -0.    0.\n",
    "   0.    0.    0.    0.  ]]\n",
    "Is this a distribution? True\n",
    "Most likely state: 0\n",
    "probability of being in the last level: 0.12493248575731676\n",
    "\n",
    "Is u* * P = u*? True\n",
    "- Mgostop - select go half of the time -\n",
    "[[ 0.24 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.02  0.04\n",
    "  -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.03  0.    0.04 -0.\n",
    "  -0.   -0.   -0.   -0.   -0.   -0.    0.03  0.    0.    0.05 -0.   -0.\n",
    "  -0.   -0.   -0.   -0.    0.03  0.    0.    0.01  0.07 -0.   -0.   -0.\n",
    "  -0.   -0.    0.01  0.    0.01  0.01  0.01  0.05 -0.   -0.   -0.   -0.\n",
    "   0.01  0.    0.01  0.01  0.01  0.    0.05 -0.   -0.   -0.    0.01  0.\n",
    "   0.    0.01  0.01  0.01  0.    0.05 -0.   -0.    0.01  0.    0.    0.\n",
    "   0.01  0.01  0.01  0.    0.05 -0.    0.01  0.    0.    0.01  0.01  0.01\n",
    "   0.01  0.02  0.02 -0.  ]]\n",
    "Is this a distribution? True\n",
    "Most likely state: 0\n",
    "probability of being in the last level: 0.08293059995179561\n",
    "\n",
    "Is u* * P = u*? True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEC7WTNu8YTO"
   },
   "source": [
    "To complement Activity 3, you will now empirically establish that the chain is ergodic, i.e., no matter where the player starts, its visitation frequency will eventually converge to the stationary distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 4.\n",
    "\n",
    "Write a function `compute_dist` that receives, as inputs,\n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a numpy array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the chain is expected to take.\n",
    "\n",
    "Your function should return, as output, a row vector (a `numpy` array) containing the distribution after $N$ steps of the chain. Use your function to justify that the chain is ergodic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DmkfmGl98YTP",
    "outputId": "c7c60033-e540-4aaf-a956-975a7be703a3",
    "ExecuteTime": {
     "end_time": "2025-03-08T13:06:55.880661Z",
     "start_time": "2025-03-08T13:06:55.871839Z"
    }
   },
   "source": [
    "# Add your code here.\n",
    "def compute_dist(markov_chain, u0, N):\n",
    "    matrix_N = np.linalg.matrix_power(markov_chain[1], N)\n",
    "    final_distribution = np.dot(u0, matrix_N)\n",
    "\n",
    "    return final_distribution"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:10:55.961549Z",
     "start_time": "2025-03-08T13:10:55.867699Z"
    }
   },
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "REPETITIONS = 5\n",
    "\n",
    "print('- Mgo - always select go -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgo[0])\n",
    "u_star = stationary_dist(Mgo)\n",
    "\n",
    "# Repeat a number of times\n",
    "for n in range(REPETITIONS):\n",
    "\n",
    "    print('\\n- Repetition', n + 1, 'of', REPETITIONS, '-')\n",
    "\n",
    "    # Initial random distribution\n",
    "    u = rnd.random((1, nS))\n",
    "    u = u / np.sum(u)\n",
    "\n",
    "    # Distrbution after 100 steps\n",
    "    v = compute_dist(Mgo, u, 100)\n",
    "    print('Is u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "    # Distrbution after 100 steps\n",
    "    v = compute_dist(Mgo, u, 200)\n",
    "    print('Is u * P^2000 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgostop[0])\n",
    "u_star = stationary_dist(Mgostop)\n",
    "\n",
    "# Repeat a number of times\n",
    "for n in range(REPETITIONS):\n",
    "\n",
    "    print('\\n- Repetition', n + 1, 'of', REPETITIONS, '-')\n",
    "\n",
    "    # Initial random distribution\n",
    "    u = rnd.random((1, nS))\n",
    "    u = u / np.sum(u)\n",
    "\n",
    "    # Distrbution after 100 steps\n",
    "    v = compute_dist(Mgostop, u, 100)\n",
    "    print('Is u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "    # Distrbution after 2000 steps\n",
    "    v = compute_dist(Mgostop, u, 200)\n",
    "    print('Is u * P^2000 = u*?', np.all(np.isclose(v, u_star)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mgo - always select go -\n",
      "\n",
      "- Repetition 1 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 2 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 3 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 4 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 5 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "- Mgostop - select go half of the time -\n",
      "\n",
      "- Repetition 1 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 2 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 3 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 4 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n",
      "\n",
      "- Repetition 5 of 5 -\n",
      "Is u * P^100 = u*? True\n",
      "Is u * P^2000 = u*? True\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBm9rlz-8YTQ"
   },
   "source": [
    "<font color='blue'>Write your answer here: A Markov Chain is considered ergodic when, regardless of the starting state (or initial distribution), the system will settle into a stable, long-term distribution as the number of steps increases. In simpler terms, no matter where we begin in the chain, as we run more and more steps, the system's probabilities will approach a fixed state — the stationary distribution.\n",
    "\n",
    "To observe this, we can run the function with different random starting distributions and let the chain run for many steps. As the number of steps grows, the resulting probability distribution will become nearly identical to the stationary distribution, regardless of the initial state. This behavior is a key characteristic of ergodic chains, showing that they \"forget\" their starting point over time and stabilize into the same long-term distribution.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP3jPIwK8YTR"
   },
   "source": [
    "Example of application of the function.\n",
    "\n",
    "```python\n",
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "REPETITIONS = 5\n",
    "\n",
    "print('- Mgo - always select go -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgo[0])\n",
    "u_star = stationary_dist(Mgo)\n",
    "\n",
    "# Repeat a number of times\n",
    "for n in range(REPETITIONS):\n",
    "\n",
    "    print('\\n- Repetition', n + 1, 'of', REPETITIONS, '-')\n",
    "\n",
    "    # Initial random distribution\n",
    "    u = rnd.random((1, nS))\n",
    "    u = u / np.sum(u)\n",
    "\n",
    "    # Distrbution after 10 steps\n",
    "    v = compute_dist(Mgo, u, 100)\n",
    "    print('Is u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "    # Distrbution after 100 steps\n",
    "    v = compute_dist(Mgo, u, 200)\n",
    "    print('Is u * P^2000 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgostop[0])\n",
    "u_star = stationary_dist(Mgostop)\n",
    "\n",
    "# Repeat a number of times\n",
    "for n in range(REPETITIONS):\n",
    "\n",
    "    print('\\n- Repetition', n + 1, 'of', REPETITIONS, '-')\n",
    "\n",
    "    # Initial random distribution\n",
    "    u = rnd.random((1, nS))\n",
    "    u = u / np.sum(u)\n",
    "\n",
    "    # Distrbution after 100 steps\n",
    "    v = compute_dist(Mgostop, u, 100)\n",
    "    print('Is u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "    # Distrbution after 2000 steps\n",
    "    v = compute_dist(Mgostop, u, 200)\n",
    "    print('Is u * P^2000 = u*?', np.all(np.isclose(v, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "````\n",
    "- Mgo - always select go -\n",
    "\n",
    "- Repetition 1 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 2 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 3 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 4 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 5 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "- Mgostop - select go half of the time -\n",
    "\n",
    "- Repetition 1 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 2 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 3 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 4 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "\n",
    "- Repetition 5 of 5 -\n",
    "Is u * P^100 = u*? True\n",
    "Is u * P^2000 = u*? True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gyb0O318YTS"
   },
   "source": [
    "### 3. Simulation\n",
    "\n",
    "In this part of the lab, you will *simulate* the actual player, and empirically compute the visitation frequency of each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sfWz3IG8YTS"
   },
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "Write down a function `simulate` that receives, as inputs,\n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a `numpy` array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the chain is expected to take.\n",
    "\n",
    "Your function should return, as output, a tuple containing a trajectory with $N$ states, where the initial state is sampled according to the initial distribution provided. Each element in the tuple should be a string corresponding to a state index.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You may find useful to import the numpy module `numpy.random`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6YrmdxqK8YTT",
    "outputId": "90c88847-ce35-4895-9e06-58ca6b778f95",
    "ExecuteTime": {
     "end_time": "2025-03-08T13:23:21.898998Z",
     "start_time": "2025-03-08T13:23:21.892332Z"
    }
   },
   "source": [
    "# Add your code here.\n",
    "def simulate(markov_chain, u0, N):\n",
    "    probs = markov_chain[1]\n",
    "    states = markov_chain[0]\n",
    "    current_state = np.random.choice(states, 1, p=u0[0]) # ['88']\n",
    "    trajectory = [current_state[0]]\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        next_state = np.random.choice(states, 1, p=probs[int(current_state[0])])\n",
    "        trajectory.append(next_state[0])\n",
    "        current_state = next_state\n",
    "\n",
    "    return tuple(trajectory)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:23:24.984220Z",
     "start_time": "2025-03-08T13:23:23.677069Z"
    }
   },
   "source": [
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "print('- Mgo - always select go -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgo[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS # [[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01...\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(Mgo, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(Mgo, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgostop[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(Mgostop, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(Mgostop, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Mgo - always select go -\n",
      "Small trajectory: ('37', '77', '97', '0', '0', '0', '0', '40', '70', '90')\n",
      "End of large trajectory: ('20', '30', '0', '30', '50', '90', '0', '30', '60', '90')\n",
      "- Mgostop - select go half of the time -\n",
      "Small trajectory: ('88', '98', '0', '0', '0', '0', '0', '0', '0', '0')\n",
      "End of large trajectory: ('22', '22', '22', '22', '22', '52', '72', '92', '0', '0')\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szkwK8VO8YTU"
   },
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "import numpy.random as rnd\n",
    "\n",
    "rnd.seed(42)\n",
    "\n",
    "print('- Mgo - always select go -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgo[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(Mgo, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(Mgo, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])\n",
    "\n",
    "print('- Mgostop - select go half of the time -')\n",
    "\n",
    "# Number of states\n",
    "nS = len(Mgostop[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(Mgostop, u, 10)\n",
    "print('Small trajectory:', traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(Mgostop, u, 10000)\n",
    "print('End of large trajectory:', traj[-10:])\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "- Mgo - always select go -\n",
    "Small trajectory: ('37', '77', '97', '0', '0', '0', '0', '40', '70', '90')\n",
    "End of large trajectory: ('20', '30', '0', '30', '50', '90', '0', '30', '60', '90')\n",
    "- Mgostop - select go half of the time -\n",
    "Small trajectory: ('88', '98', '0', '0', '0', '0', '0', '0', '0', '0')\n",
    "End of large trajectory: ('22', '22', '22', '22', '22', '52', '72', '92', '0', '0')\n",
    "```\n",
    "\n",
    "Note that, even if the seed is fixed, it is possible that your trajectories are slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "We will now compare the relative speed of two chains.\n",
    "Create two chains, one where we always choose Go and another where we choose Go 3/4 of the time and Stop 1/4 of the time.\n",
    "\n",
    "Which one is faster? Verify using one sampling approach, and one analytical approach.\n",
    "\n",
    "Is the best way to choose the action the same for the game with 20% rainy days ('StopITSpider02.npy') and the game with 40% rainy days?.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:34:28.077063Z",
     "start_time": "2025-03-08T13:34:28.061408Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Load chains: 20% rainy days\n",
    "M1_1 = load_chain('StopITSpider02.npy', 1)\n",
    "M3_4 = load_chain('StopITSpider02.npy', 3/4)\n",
    "\n",
    "# Compute stationary distributions\n",
    "stat_dist_m11 = stationary_dist(M1_1)\n",
    "stat_dist_m34 = stationary_dist(M3_4)\n",
    "\n",
    "# Define states 90 to 99\n",
    "states_90_99 = [str(i) for i in range(90, 100)]\n",
    "\n",
    "# Get state space for each chain\n",
    "M1_1_0 = M1_1[0]\n",
    "M3_4_0 = M3_4[0]\n",
    "\n",
    "# Measure time for M1_1 sum calculation\n",
    "start_time_m11 = time.time()  # Start time for M1_1 calculation\n",
    "sum_m11 = np.sum([stat_dist_m11[M1_1_0.index(state)] for state in states_90_99])\n",
    "end_time_m11 = time.time()  # End time for M1_1 calculation\n",
    "time_m11 = end_time_m11 - start_time_m11  # Calculate execution time for M1_1\n",
    "\n",
    "# Measure time for M3_4 sum calculation\n",
    "start_time_m34 = time.time()  # Start time for M3_4 calculation\n",
    "sum_m34 = np.sum([stat_dist_m34[M3_4_0.index(state)] for state in states_90_99])\n",
    "end_time_m34 = time.time()  # End time for M3_4 calculation\n",
    "time_m34 = end_time_m34 - start_time_m34  # Calculate execution time for M3_4\n",
    "\n",
    "# Print analytical results\n",
    "print(\"ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M1_1 (20% rainy days):\", sum_m11)\n",
    "print(\"ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M3_4 (20% rainy days):\", sum_m34)\n",
    "\n",
    "# Compare times\n",
    "if time_m11 < time_m34:\n",
    "    print(\"M1_1 sum calculation is faster.\")\n",
    "else:\n",
    "    print(\"M3_4 sum calculation is faster.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M1_1 (20% rainy days): 0.12493248575731687\n",
      "ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M3_4 (20% rainy days): 0.11049545224077774\n",
      "M3_4 sum calculation is faster.\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:35:38.301283Z",
     "start_time": "2025-03-08T13:35:37.193997Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Definir o número de estados\n",
    "nS = len(M1_1[0])\n",
    "\n",
    "# Distribuição inicial uniforme\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Número de passos da simulação\n",
    "N = 10000\n",
    "\n",
    "# Definir os estados de interesse (90 a 99)\n",
    "states_90_99 = [str(i) for i in range(90, 100)]\n",
    "\n",
    "# Medir o tempo para simular a trajetória para M1_1\n",
    "start_time_m11_sim = time.time()  # Início da simulação para M1_1\n",
    "traj1_1 = simulate(M1_1, u, N)\n",
    "end_time_m11_sim = time.time()  # Fim da simulação para M1_1\n",
    "time_m11_sim = end_time_m11_sim - start_time_m11_sim  # Tempo de execução para M1_1\n",
    "\n",
    "# Medir o tempo para simular a trajetória para M3_4\n",
    "start_time_m34_sim = time.time()  # Início da simulação para M3_4\n",
    "traj3_4 = simulate(M3_4, u, N)\n",
    "end_time_m34_sim = time.time()  # Fim da simulação para M3_4\n",
    "time_m34_sim = end_time_m34_sim - start_time_m34_sim  # Tempo de execução para M3_4\n",
    "\n",
    "# Contar o número de vezes que os estados 90 a 99 aparecem nas trajetórias\n",
    "count_90_99_1_1 = sum(1 for state in traj1_1 if state in states_90_99)\n",
    "count_90_99_3_4 = sum(1 for state in traj3_4 if state in states_90_99)\n",
    "\n",
    "# Calcular a probabilidade nos estados 90 a 99\n",
    "prob_90_99_1_1 = count_90_99_1_1 / N\n",
    "prob_90_99_3_4 = count_90_99_3_4 / N\n",
    "\n",
    "# Exibir os resultados da abordagem de amostragem\n",
    "print(\"SAMPLING APPROACH: Probability in states 90 to 99 for M1_1 (20% rainy days):\", prob_90_99_1_1)\n",
    "print(\"SAMPLING APPROACH: Probability in states 90 to 99 for M3_4 (20% rainy days):\", prob_90_99_3_4)\n",
    "\n",
    "if time_m11_sim < time_m34_sim:\n",
    "    print(\"M1_1 simulation is faster.\")\n",
    "else:\n",
    "    print(\"M3_4 simulation is faster.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLING APPROACH: Probability in states 90 to 99 for M1_1 (20% rainy days): 0.1247\n",
      "SAMPLING APPROACH: Probability in states 90 to 99 for M3_4 (20% rainy days): 0.1072\n",
      "M1_1 simulation is faster.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:36:12.308364Z",
     "start_time": "2025-03-08T13:36:12.291964Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Load chains: 40% rainy days\n",
    "M1_1 = load_chain('StopITSpider04.npy', 1)\n",
    "M3_4 = load_chain('StopITSpider04.npy', 3/4)\n",
    "\n",
    "# Compute stationary distributions\n",
    "stat_dist_m11 = stationary_dist(M1_1)\n",
    "stat_dist_m34 = stationary_dist(M3_4)\n",
    "\n",
    "# Define states 90 to 99\n",
    "states_90_99 = [str(i) for i in range(90, 100)]\n",
    "\n",
    "# Get state space for each chain\n",
    "M1_1_0 = M1_1[0]\n",
    "M3_4_0 = M3_4[0]\n",
    "\n",
    "# Measure time for M1_1 sum calculation\n",
    "start_time_m11 = time.time()  # Start time for M1_1 calculation\n",
    "sum_m11 = np.sum([stat_dist_m11[M1_1_0.index(state)] for state in states_90_99])\n",
    "end_time_m11 = time.time()  # End time for M1_1 calculation\n",
    "time_m11 = end_time_m11 - start_time_m11  # Calculate execution time for M1_1\n",
    "\n",
    "# Measure time for M3_4 sum calculation\n",
    "start_time_m34 = time.time()  # Start time for M3_4 calculation\n",
    "sum_m34 = np.sum([stat_dist_m34[M3_4_0.index(state)] for state in states_90_99])\n",
    "end_time_m34 = time.time()  # End time for M3_4 calculation\n",
    "time_m34 = end_time_m34 - start_time_m34  # Calculate execution time for M3_4\n",
    "\n",
    "# Print analytical results\n",
    "print(\"ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M1_1 (40% rainy days):\", sum_m11)\n",
    "print(\"ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M3_4 (40% rainy days):\", sum_m34)\n",
    "\n",
    "# Compare times\n",
    "if time_m11 < time_m34:\n",
    "    print(\"M1_1 sum calculation is faster.\")\n",
    "else:\n",
    "    print(\"M3_4 sum calculation is faster.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M1_1 (40% rainy days): 0.061803808840557375\n",
      "ANALYTICAL APPROACH: Sum of probabilities in states 90 to 99 for M3_4 (40% rainy days): 0.07032542473662177\n",
      "M3_4 sum calculation is faster.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:36:37.964396Z",
     "start_time": "2025-03-08T13:36:36.691232Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "# Definir o número de estados\n",
    "nS = len(M1_1[0])\n",
    "\n",
    "# Distribuição inicial uniforme\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Número de passos da simulação\n",
    "N = 10000\n",
    "\n",
    "# Definir os estados de interesse (90 a 99)\n",
    "states_90_99 = [str(i) for i in range(90, 100)]\n",
    "\n",
    "# Medir o tempo para simular a trajetória para M1_1\n",
    "start_time_m11_sim = time.time()  # Início da simulação para M1_1\n",
    "traj1_1 = simulate(M1_1, u, N)\n",
    "end_time_m11_sim = time.time()  # Fim da simulação para M1_1\n",
    "time_m11_sim = end_time_m11_sim - start_time_m11_sim  # Tempo de execução para M1_1\n",
    "\n",
    "# Medir o tempo para simular a trajetória para M3_4\n",
    "start_time_m34_sim = time.time()  # Início da simulação para M3_4\n",
    "traj3_4 = simulate(M3_4, u, N)\n",
    "end_time_m34_sim = time.time()  # Fim da simulação para M3_4\n",
    "time_m34_sim = end_time_m34_sim - start_time_m34_sim  # Tempo de execução para M3_4\n",
    "\n",
    "# Contar o número de vezes que os estados 90 a 99 aparecem nas trajetórias\n",
    "count_90_99_1_1 = sum(1 for state in traj1_1 if state in states_90_99)\n",
    "count_90_99_3_4 = sum(1 for state in traj3_4 if state in states_90_99)\n",
    "\n",
    "# Calcular a probabilidade nos estados 90 a 99\n",
    "prob_90_99_1_1 = count_90_99_1_1 / N\n",
    "prob_90_99_3_4 = count_90_99_3_4 / N\n",
    "\n",
    "# Exibir os resultados da abordagem de amostragem\n",
    "print(\"SAMPLING APPROACH: Probability in states 90 to 99 for M1_1 (40% rainy days):\", prob_90_99_1_1)\n",
    "print(\"SAMPLING APPROACH: Probability in states 90 to 99 for M3_4 (40% rainy days):\", prob_90_99_3_4)\n",
    "\n",
    "if time_m11_sim < time_m34_sim:\n",
    "    print(\"M1_1 simulation is faster.\")\n",
    "else:\n",
    "    print(\"M3_4 simulation is faster.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLING APPROACH: Probability in states 90 to 99 for M1_1 (40% rainy days): 0.0614\n",
      "SAMPLING APPROACH: Probability in states 90 to 99 for M3_4 (40% rainy days): 0.0727\n",
      "M1_1 simulation is faster.\n"
     ]
    }
   ],
   "execution_count": 67
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
